# -*- coding: utf-8 -*-
"""22.11.4678_ZidanDhiyaUlHaq_UASBDDM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cBb_ILQArVLqETCa0dL5D7hA8peGTubw
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.metrics import confusion_matrix, classification_report
import joblib
import json
import warnings
warnings.filterwarnings('ignore')

# Load the data
df = pd.read_csv('topuniversities.csv')

# Check data types and info
print("=== Data Info ===")
print(df.info())

print("\n=== Null Values ===")
print(df.isnull().sum())

# Drop rows with missing values
df = df.dropna()

# Basic statistics summary
print("\n=== Data Summary ===")
print(df.describe())

# Calculate correlation matrix
correlation_matrix = df.select_dtypes(include=[np.number]).corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.tight_layout()
plt.show()

# Bar chart of top 10 universities by overall score
plt.figure(figsize=(12, 6))
top_10 = df.head(10)
plt.bar(top_10['University Name'], top_10['Overall Score'])
plt.xticks(rotation=45, ha='right')
plt.title('Top 10 Universities by Overall Score')
plt.tight_layout()
plt.show()

# Pie chart of universities by country
country_counts = df['Country'].value_counts()
plt.figure(figsize=(10, 10))
plt.pie(country_counts.values, labels=country_counts.index, autopct='%1.1f%%')
plt.title('Distribution of Universities by Country')
plt.show()

# Box plot of Overall Score by Country
plt.figure(figsize=(12, 6))
sns.boxplot(x='Country', y='Overall Score', data=df)
plt.xticks(rotation=45)
plt.title('Overall Score Distribution by Country')
plt.tight_layout()
plt.show()

# Scatter plot of Citations per Paper vs Overall Score
plt.figure(figsize=(10, 6))
plt.scatter(df['Citations per Paper'], df['Overall Score'])
plt.xlabel('Citations per Paper')
plt.ylabel('Overall Score')
plt.title('Citations per Paper vs Overall Score')
plt.show()

# Select features based on our goals (identifying key factors affecting university rankings)
selected_features = [
    'Citations per Paper',
    'Papers per Faculty',
    'Academic Reputation',
    'Faculty Student Ratio',
    'Staff with PhD',
    'International Research Center',
    'International Students',
    'International Faculty',
    'Employer Reputation'
]

# Prepare features and target
X = df[selected_features]

# Create ranking groups (Top, Middle, Lower tier universities)
y = pd.qcut(df['Overall Score'], q=3, labels=['Top', 'Middle', 'Lower'])

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Initialize and train QDA model
qda_model = QuadraticDiscriminantAnalysis()
qda_model.fit(X_train, y_train)

# Make predictions
y_pred = qda_model.predict(X_test)

# Model Evaluation
print("=== Model Performance Analysis ===")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix Visualization
plt.figure(figsize=(10, 8))
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Top', 'Middle', 'Lower'],
            yticklabels=['Top', 'Middle', 'Lower'])
plt.title('QDA Model Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Cross-validation scores
cv_scores = cross_val_score(qda_model, X_scaled, y, cv=5)
print(f"\nCross-validation scores: {cv_scores}")
print(f"Average CV score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")

# Feature importance analysis
class_means = []
for class_label in np.unique(y):
    class_data = X[y == class_label]
    class_means.append(class_data.mean())

class_means_df = pd.DataFrame(class_means,
                            columns=selected_features,
                            index=['Top', 'Middle', 'Lower'])

# Visualize feature importance
plt.figure(figsize=(12, 6))
sns.heatmap(class_means_df, annot=True, cmap='RdYlBu', center=0)
plt.title('Feature Importance by University Tier')
plt.tight_layout()
plt.show()

# Save the model and scaler
model_path = 'university_qda_model.joblib'
scaler_path = 'university_scaler.joblib'
joblib.dump(qda_model, model_path)
joblib.dump(scaler, scaler_path)

# Function to make predictions for new universities
def predict_university_tier(features_dict):
    """
    Predict university tier based on input features.

    Parameters:
    features_dict (dict): Dictionary containing university features

    Returns:
    str: Predicted university tier
    """
    # Convert input to correct format
    features = [features_dict[feature] for feature in selected_features]
    features_array = np.array(features).reshape(1, -1)

    # Scale features
    scaled_features = scaler.transform(features_array)

    # Make prediction
    prediction = qda_model.predict(scaled_features)

    return prediction[0]

# Example usage
print("\n=== Example Prediction ===")
example_university = {
    'Citations per Paper': 90.0,
    'Papers per Faculty': 85.0,
    'Academic Reputation': 95.0,
    'Faculty Student Ratio': 88.0,
    'Staff with PhD': 92.0,
    'International Research Center': 89.0,
    'International Students': 80.0,
    'International Faculty': 85.0,
    'Employer Reputation': 93.0
}

predicted_tier = predict_university_tier(example_university)
print(f"Predicted University Tier: {predicted_tier}")

# Save model information
model_info = {
    'features': selected_features,
    'model_path': model_path,
    'scaler_path': scaler_path,
    'performance': {
        'cv_scores_mean': cv_scores.mean(),
        'cv_scores_std': cv_scores.std()
    }
}

# Save model information to JSON
with open('model_info.json', 'w') as f:
    json.dump(model_info, f, indent=4)

print("\n=== Model Saved ===")
print(f"Model saved as: {model_path}")
print(f"Scaler saved as: {scaler_path}")
print("Model information saved as: model_info.json")